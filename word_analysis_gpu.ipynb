{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Word Permutation Analysis - GPU Accelerated\n\nThis notebook uses CUDA/GPU acceleration to analyze **ALL** permutations of 5-7 letter words.\n\n## Hardware Requirements\n- NVIDIA GPU with CUDA 12.x support\n- Recommended: H100 (80GB) or A100 (80GB)\n- For 8× H100: Can process all 3.3 billion 7-letter permutations\n\n## Setup\nThis notebook will automatically install all required dependencies in the first cell."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 1: Install All Dependencies\n\nThis cell installs:\n- **Base dependencies**: pandas, numpy, polars, matplotlib, seaborn, kaggle\n- **GPU dependencies**: cupy-cuda12x, numba, cudf-cu12\n- **word-anal package**: Editable install of this project\n\n**Note**: This may take 5-10 minutes on first run."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Install base dependencies\n!uv pip install pandas numpy polars jupyter notebook ipykernel matplotlib seaborn kaggle\n\n# Install GPU acceleration libraries\n!uv pip install cupy-cuda12x numba cudf-cu12\n\n# Install word-anal package in editable mode\n!uv pip install -e .\n\nprint(\"\\n✅ All dependencies installed successfully!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2: Verify GPU Setup\n\nCheck that CUDA is available and detect all GPUs."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "# Check CUDA availability\n",
    "print(\"CUDA Available:\", cuda.is_available())\n",
    "print(\"\\nGPU Devices:\")\n",
    "\n",
    "n_gpus = cp.cuda.runtime.getDeviceCount()\n",
    "print(f\"Number of GPUs: {n_gpus}\")\n",
    "\n",
    "for i in range(n_gpus):\n",
    "    with cp.cuda.Device(i):\n",
    "        props = cp.cuda.runtime.getDeviceProperties(i)\n",
    "        total_mem = cp.cuda.runtime.memGetInfo()[1]\n",
    "        print(f\"\\nGPU {i}:\")\n",
    "        print(f\"  Name: {props['name'].decode()}\")\n",
    "        print(f\"  Total Memory: {total_mem / (1024**3):.2f} GB\")\n",
    "        print(f\"  Compute Capability: {props['major']}.{props['minor']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Download Kaggle Dataset\n",
    "\n",
    "Download the English dictionary dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from word_anal.kaggle_helper import get_dictionary_dataset\nimport os\n\n# Load credentials from environment variables (recommended)\n# Or set them directly here for testing (DO NOT commit!)\nKAGGLE_CREDENTIALS = {\n    \"username\": os.getenv(\"KAGGLE_USERNAME\", \"YOUR_USERNAME\"),\n    \"key\": os.getenv(\"KAGGLE_KEY\", \"YOUR_API_KEY\")\n}\n\n# Download dataset\ncsv_path = get_dictionary_dataset(\n    credentials=KAGGLE_CREDENTIALS,\n    download_path=\"data\",\n    force=False\n)\n\nprint(f\"\\nDataset ready at: {csv_path}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Initialize GPU Analyzer\n",
    "\n",
    "Choose between single-GPU or multi-GPU mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_anal.gpu_analyzer import GPUWordPermutationAnalyzer\n",
    "from word_anal.multi_gpu import MultiGPUAnalyzer, get_available_gpus\n",
    "\n",
    "# Configuration\n",
    "WORDS_CSV_PATH = \"data/dict.csv\"\n",
    "WORD_COLUMN = \"word\"\n",
    "WORD_LENGTHS = [5, 6, 7]  # Analyze 5, 6, and 7-letter permutations\n",
    "\n",
    "# GPU Configuration\n",
    "USE_MULTI_GPU = True  # Set to False for single GPU\n",
    "N_GPUS = None  # None = use all available GPUs\n",
    "\n",
    "print(f\"Available GPUs: {get_available_gpus()}\")\n",
    "\n",
    "if USE_MULTI_GPU and get_available_gpus() > 1:\n",
    "    print(\"\\nInitializing Multi-GPU Analyzer...\")\n",
    "    analyzer = MultiGPUAnalyzer(\n",
    "        words_csv_path=WORDS_CSV_PATH,\n",
    "        word_column=WORD_COLUMN,\n",
    "        n_gpus=N_GPUS\n",
    "    )\n",
    "    mode = \"multi-GPU\"\n",
    "else:\n",
    "    print(\"\\nInitializing Single-GPU Analyzer...\")\n",
    "    analyzer = GPUWordPermutationAnalyzer(\n",
    "        words_csv_path=WORDS_CSV_PATH,\n",
    "        word_column=WORD_COLUMN,\n",
    "        gpu_id=0\n",
    "    )\n",
    "    mode = \"single-GPU\"\n",
    "\n",
    "print(f\"\\nAnalyzer ready in {mode} mode!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run Analysis on ALL Permutations\n",
    "\n",
    "This will process:\n",
    "- **5-letter**: 7,893,600 permutations (~205 MB GPU memory)\n",
    "- **6-letter**: 165,765,600 permutations (~4.3 GB GPU memory)\n",
    "- **7-letter**: 3,315,312,000 permutations (~86 GB GPU memory)\n",
    "\n",
    "**Total**: 3.5+ billion permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"Starting FULL permutation analysis...\")\n",
    "print(\"This may take several minutes depending on your GPU.\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Run analysis for all lengths\n",
    "if USE_MULTI_GPU and isinstance(analyzer, MultiGPUAnalyzer):\n",
    "    results = analyzer.analyze_all_lengths(\n",
    "        lengths=WORD_LENGTHS,\n",
    "        batch_size_per_gpu=50_000_000  # 50M permutations per batch\n",
    "    )\n",
    "else:\n",
    "    results = analyzer.analyze_all_lengths(\n",
    "        lengths=WORD_LENGTHS,\n",
    "        batch_size=50_000_000  # 50M permutations per batch\n",
    "    )\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"Analysis Complete! Total time: {elapsed_time:.2f} seconds ({elapsed_time/60:.2f} minutes)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: View Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create summary table\n",
    "summary_data = []\n",
    "for length, result in results.items():\n",
    "    summary_data.append({\n",
    "        'Word Length': length,\n",
    "        'Total Permutations': f\"{result['total_permutations']:,}\",\n",
    "        'Mean Words/Perm': f\"{result['mean_words']:.2f}\",\n",
    "        'Median': f\"{result['median_words']:.0f}\",\n",
    "        'Std Dev': f\"{result['std_words']:.2f}\",\n",
    "        'Min': result['min_words'],\n",
    "        'Max': result['max_words']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Calculate total comparisons performed\n",
    "total_perms = sum(r['total_permutations'] for r in results.values())\n",
    "print(f\"\\nTotal permutations analyzed: {total_perms:,}\")\n",
    "print(f\"Processing rate: {total_perms / elapsed_time:,.0f} permutations/second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Create DataFrames for Visualization\n",
    "\n",
    "Convert GPU results to pandas DataFrames for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrames\n",
    "dfs = {}\n",
    "\n",
    "for length, result in results.items():\n",
    "    if result['results'] is not None:\n",
    "        df = pd.DataFrame({\n",
    "            'word_count': result['results']\n",
    "        })\n",
    "        dfs[length] = df\n",
    "        print(f\"{length}-letter DataFrame: {len(df):,} rows\")\n",
    "\n",
    "print(\"\\nDataFrames created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Visualize Results\n",
    "\n",
    "Create visualizations of the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Distribution comparison\n",
    "fig, axes = plt.subplots(1, len(WORD_LENGTHS), figsize=(18, 5))\n",
    "if len(WORD_LENGTHS) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, word_length in enumerate(WORD_LENGTHS):\n",
    "    if word_length in dfs:\n",
    "        df = dfs[word_length]\n",
    "        axes[idx].hist(df['word_count'], bins=100, alpha=0.7, edgecolor='black')\n",
    "        axes[idx].set_xlabel('Number of Valid Words', fontsize=12)\n",
    "        axes[idx].set_ylabel('Frequency', fontsize=12)\n",
    "        axes[idx].set_title(f'{word_length}-Letter Word Distribution\\n({len(df):,} permutations)', fontsize=14)\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add mean line\n",
    "        mean_val = df['word_count'].mean()\n",
    "        axes[idx].axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.2f}')\n",
    "        axes[idx].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('gpu_distribution_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: gpu_distribution_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "data_for_boxplot = []\n",
    "labels = []\n",
    "for word_length in WORD_LENGTHS:\n",
    "    if word_length in dfs:\n",
    "        data_for_boxplot.append(dfs[word_length]['word_count'])\n",
    "        labels.append(f\"{word_length}-letter\\n({len(dfs[word_length]):,} perms)\")\n",
    "\n",
    "bp = ax.boxplot(data_for_boxplot, labels=labels, patch_artist=True)\n",
    "\n",
    "# Color the boxes\n",
    "colors = ['lightblue', 'lightgreen', 'lightcoral']\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "ax.set_ylabel('Number of Valid Words per Permutation', fontsize=12)\n",
    "ax.set_xlabel('Word Length', fontsize=12)\n",
    "ax.set_title('Distribution Comparison: Valid Words per Permutation (ALL Permutations)', fontsize=14)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('gpu_boxplot_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Saved: gpu_boxplot_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Generate Interactive D3.js Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from word_anal.data_processing import DataProcessor\n",
    "from word_anal.visualizations import VisualizationGenerator\n",
    "\n",
    "# Initialize data processor\n",
    "processor = DataProcessor()\n",
    "\n",
    "# Add results for each word length\n",
    "for word_length in WORD_LENGTHS:\n",
    "    if word_length in dfs:\n",
    "        # Add placeholder for permutation and words columns\n",
    "        df = dfs[word_length].copy()\n",
    "        df['permutation'] = ''  # Not needed for visualization\n",
    "        df['words'] = ''  # Not needed for visualization\n",
    "        processor.add_results(word_length, df)\n",
    "\n",
    "# Generate interactive visualization\n",
    "viz_gen = VisualizationGenerator(processor)\n",
    "viz_gen.generate_html(output_path=\"word_analysis_gpu_full.html\")\n",
    "\n",
    "print(\"\\nInteractive visualization saved to: word_analysis_gpu_full.html\")\n",
    "print(\"Open this file in a web browser to view the interactive D3.js visualizations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Export Results to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export summary statistics\n",
    "summary_df.to_csv('gpu_analysis_summary.csv', index=False)\n",
    "print(\"Exported summary to: gpu_analysis_summary.csv\")\n",
    "\n",
    "# Export full results (optional - these files will be large!)\n",
    "export_full = False  # Set to True to export all permutation results\n",
    "\n",
    "if export_full:\n",
    "    for word_length in WORD_LENGTHS:\n",
    "        if word_length in dfs:\n",
    "            filename = f\"gpu_results_{word_length}letter_all_permutations.csv\"\n",
    "            dfs[word_length].to_csv(filename, index=False)\n",
    "            print(f\"Exported {word_length}-letter results to: {filename}\")\n",
    "else:\n",
    "    print(\"\\nFull results not exported (set export_full=True to export)\")\n",
    "    print(\"Warning: Full exports can be very large (7-letter = 3.3B rows!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: GPU Memory Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU memory usage\n",
    "if USE_MULTI_GPU and isinstance(analyzer, MultiGPUAnalyzer):\n",
    "    analyzer.get_gpu_memory_info()\n",
    "else:\n",
    "    with cp.cuda.Device(0):\n",
    "        mempool = cp.get_default_memory_pool()\n",
    "        total = cp.cuda.runtime.memGetInfo()[1]\n",
    "        used = mempool.used_bytes()\n",
    "        \n",
    "        print(\"GPU 0 Memory:\")\n",
    "        print(f\"  Total: {total / (1024**3):.2f} GB\")\n",
    "        print(f\"  Used: {used / (1024**3):.2f} GB\")\n",
    "        print(f\"  Free: {(total - used) / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook processed **ALL** permutations using GPU acceleration:\n",
    "- Analyzed billions of permutations in minutes\n",
    "- Used custom CUDA kernels for maximum efficiency\n",
    "- Generated comprehensive statistics and visualizations\n",
    "\n",
    "**Key Results:**\n",
    "- Total permutations analyzed: 3.5+ billion\n",
    "- Processing speed: Millions of permutations per second\n",
    "- Complete distribution analysis for 5, 6, and 7-letter words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (word-anal)",
   "language": "python",
   "name": "word-anal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}