{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Permutation Analysis\n",
    "\n",
    "This notebook analyzes how many valid English words can be formed from different permutations of 5-7 letters in the alphabet.\n",
    "\n",
    "## Overview\n",
    "- Load valid English words from CSV\n",
    "- Generate permutations of letters\n",
    "- Count valid words for each permutation\n",
    "- Visualize distributions across different word lengths\n",
    "- Compare 5-letter, 6-letter, and 7-letter word patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Import required libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from word_anal.analyzer import WordPermutationAnalyzer\n",
    "from word_anal.data_processing import DataProcessor\n",
    "from word_anal.visualizations import VisualizationGenerator\n",
    "from word_anal.kaggle_helper import get_dictionary_dataset\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Dataset (Optional)\n",
    "Download the Kaggle English dictionary dataset\n",
    "\n",
    "**Note**: If you already have the dataset downloaded, skip this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from word_anal.kaggle_helper import get_dictionary_dataset\nimport os\n\n# Load credentials from environment variables (recommended)\n# Or set them directly here for testing (DO NOT commit!)\nKAGGLE_CREDENTIALS = {\n    \"username\": os.getenv(\"KAGGLE_USERNAME\", \"YOUR_USERNAME\"),\n    \"key\": os.getenv(\"KAGGLE_KEY\", \"YOUR_API_KEY\")\n}\n\n# Download the dataset (set force=True to re-download)\ncsv_path = get_dictionary_dataset(\n    credentials=KAGGLE_CREDENTIALS,\n    download_path=\"data\",\n    force=False\n)\n\nprint(f\"Dataset ready at: {csv_path}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Set your parameters here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the downloaded CSV file\n",
    "WORDS_CSV_PATH = \"data/dict.csv\"  # Kaggle dataset path\n",
    "WORD_COLUMN = \"word\"  # Column name in the Kaggle dataset\n",
    "\n",
    "# Analysis parameters\n",
    "WORD_LENGTHS = [5, 6, 7]  # Which word lengths to analyze\n",
    "SAMPLE_SIZE = 10000  # Number of permutations to sample per length (None for all)\n",
    "ALPHABET_SUBSET = None  # Use subset of alphabet (e.g., \"aeiou\") or None for full alphabet\n",
    "\n",
    "# Output\n",
    "HTML_OUTPUT_PATH = \"word_analysis_visualization.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Words\n",
    "Initialize the analyzer with your word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = WordPermutationAnalyzer(\n",
    "    words_csv_path=WORDS_CSV_PATH,\n",
    "    word_column=WORD_COLUMN\n",
    ")\n",
    "\n",
    "print(f\"Total valid words loaded: {len(analyzer.valid_words):,}\")\n",
    "print(f\"\\nWord count by length:\")\n",
    "for length in WORD_LENGTHS:\n",
    "    count = len(analyzer.get_words_by_length(length))\n",
    "    print(f\"  {length}-letter words: {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Analysis\n",
    "Analyze permutations for each word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the analysis\n",
    "results = analyzer.compare_word_lengths(\n",
    "    lengths=WORD_LENGTHS,\n",
    "    sample_size=SAMPLE_SIZE,\n",
    "    alphabet_subset=ALPHABET_SUBSET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data\n",
    "Prepare data for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data processor\n",
    "processor = DataProcessor()\n",
    "\n",
    "# Add results for each word length\n",
    "for word_length, df in results.items():\n",
    "    processor.add_results(word_length, df)\n",
    "\n",
    "# Display comparison statistics\n",
    "comparison_df = processor.get_comparison_data()\n",
    "print(\"\\nComparison Statistics:\")\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top and Bottom Permutations\n",
    "See which letter combinations yield the most and fewest valid words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word_length in WORD_LENGTHS:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{word_length}-LETTER WORDS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    print(f\"\\nTop 10 Permutations:\")\n",
    "    top = processor.get_top_permutations(word_length, n=10)\n",
    "    display(top[['permutation', 'word_count', 'words']])\n",
    "    \n",
    "    print(f\"\\nBottom 10 Permutations:\")\n",
    "    bottom = processor.get_bottom_permutations(word_length, n=10)\n",
    "    display(bottom[['permutation', 'word_count', 'words']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Visualizations (Matplotlib)\n",
    "Quick visualizations using matplotlib and seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution comparison\n",
    "fig, axes = plt.subplots(1, len(WORD_LENGTHS), figsize=(15, 4))\n",
    "if len(WORD_LENGTHS) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, word_length in enumerate(WORD_LENGTHS):\n",
    "    df = results[word_length]\n",
    "    axes[idx].hist(df['word_count'], bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[idx].set_xlabel('Number of Valid Words')\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].set_title(f'{word_length}-Letter Word Distribution')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plot comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "data_for_boxplot = []\n",
    "labels = []\n",
    "for word_length in WORD_LENGTHS:\n",
    "    data_for_boxplot.append(results[word_length]['word_count'])\n",
    "    labels.append(f\"{word_length}-letter\")\n",
    "\n",
    "plt.boxplot(data_for_boxplot, labels=labels)\n",
    "plt.ylabel('Number of Valid Words per Permutation')\n",
    "plt.xlabel('Word Length')\n",
    "plt.title('Distribution Comparison: Valid Words per Permutation')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "combined_data = []\n",
    "for word_length in WORD_LENGTHS:\n",
    "    df_temp = results[word_length][['word_count']].copy()\n",
    "    df_temp['word_length'] = f\"{word_length}-letter\"\n",
    "    combined_data.append(df_temp)\n",
    "\n",
    "combined_df = pd.concat(combined_data, ignore_index=True)\n",
    "sns.violinplot(data=combined_df, x='word_length', y='word_count')\n",
    "plt.ylabel('Number of Valid Words per Permutation')\n",
    "plt.xlabel('Word Length')\n",
    "plt.title('Distribution Shape Comparison')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive D3.js Visualizations\n",
    "Generate and display interactive visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization generator\n",
    "viz_gen = VisualizationGenerator(processor)\n",
    "\n",
    "# Generate HTML file\n",
    "viz_gen.generate_html(output_path=HTML_OUTPUT_PATH)\n",
    "print(f\"\\nInteractive visualization saved to: {HTML_OUTPUT_PATH}\")\n",
    "print(\"Open this file in a web browser to view the interactive D3.js visualizations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display in notebook\n",
    "viz_gen.generate_notebook_display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results\n",
    "Save processed data to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export all results to CSV\n",
    "processor.export_all_to_csv(output_dir=\".\")\n",
    "\n",
    "# Export comparison statistics\n",
    "comparison_df.to_csv(\"comparison_statistics.csv\", index=False)\n",
    "print(\"\\nExported comparison statistics to: comparison_statistics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis\n",
    "Deeper statistical insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution characteristics\n",
    "print(\"Distribution Characteristics:\\n\")\n",
    "\n",
    "for word_length in WORD_LENGTHS:\n",
    "    stats = processor.get_stats(word_length)\n",
    "    print(f\"{word_length}-letter words:\")\n",
    "    print(f\"  Skewness: {stats.skewness:.3f}\")\n",
    "    print(f\"  Kurtosis: {stats.kurtosis:.3f}\")\n",
    "    \n",
    "    if stats.skewness > 0:\n",
    "        print(f\"  → Right-skewed distribution (tail extends right)\")\n",
    "    elif stats.skewness < 0:\n",
    "        print(f\"  → Left-skewed distribution (tail extends left)\")\n",
    "    else:\n",
    "        print(f\"  → Symmetric distribution\")\n",
    "    \n",
    "    if stats.kurtosis > 0:\n",
    "        print(f\"  → Heavy tails (more outliers than normal distribution)\")\n",
    "    elif stats.kurtosis < 0:\n",
    "        print(f\"  → Light tails (fewer outliers than normal distribution)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Key findings and insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ANALYSIS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nWords analyzed: {len(analyzer.valid_words):,}\")\n",
    "print(f\"Word lengths: {', '.join(map(str, WORD_LENGTHS))}\")\n",
    "print(f\"Permutations per length: {SAMPLE_SIZE if SAMPLE_SIZE else 'All'}\")\n",
    "\n",
    "print(\"\\nKey Findings:\")\n",
    "for word_length in WORD_LENGTHS:\n",
    "    stats = processor.get_stats(word_length)\n",
    "    print(f\"\\n{word_length}-letter words:\")\n",
    "    print(f\"  Average valid words per permutation: {stats.mean:.2f}\")\n",
    "    print(f\"  Range: {stats.min} to {stats.max}\")\n",
    "    print(f\"  50% of permutations have between {stats.q25:.0f} and {stats.q75:.0f} valid words\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Analysis complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}